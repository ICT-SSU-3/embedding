# main_app.py

import asyncio
import os
from dotenv import load_dotenv
from typing import Dict, Any, List
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Gemini ëª¨ë¸ ì´ˆê¸°í™”
llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.2)
llm_semaphore = asyncio.Semaphore(1)

# --- í‰ê°€ ë…¸ë“œ í•¨ìˆ˜ë“¤ ---

async def star_agent_node(answer: str) -> str:
    print("--- â­ï¸ STAR í‰ê°€ ì‹œì‘ ---")
    prompt_template = PromptTemplate.from_template("""
    ì•„ë˜ ë‹µë³€ì„ STAR ê¸°ë²•(Situation, Task, Action, Result)ìœ¼ë¡œ í‰ê°€í•˜ê³  ì ìˆ˜ë¥¼ 10ì  ë§Œì ìœ¼ë¡œ ë¶€ì—¬í•˜ì„¸ìš”. 
    êµ¬ì„±ìš”ì†Œê°€ ì–¼ë§ˆë‚˜ ëª…í™•í•˜ê²Œ ë“œëŸ¬ë‚˜ëŠ”ì§€ì— ì§‘ì¤‘í•˜ì„¸ìš”.
    - ì ìˆ˜: [ì ìˆ˜]/10
    - í‰ê°€: [í‰ê°€ ë‚´ìš©]
    ë‹µë³€: {answer}
    """)
    chain = prompt_template | llm
    
    async with llm_semaphore:
        star_eval = await chain.ainvoke({"answer": answer})
    return star_eval.content

async def logic_agent_node(answer: str) -> str:
    print("--- ğŸ§ ë…¼ë¦¬ì„± í‰ê°€ ì‹œì‘ ---")
    prompt_template = PromptTemplate.from_template("""
    ì•„ë˜ ë‹µë³€ì˜ ë…¼ë¦¬ì„±ê³¼ ëª…í™•ì„±ì„ í‰ê°€í•˜ê³  ì ìˆ˜ë¥¼ 10ì  ë§Œì ìœ¼ë¡œ ë¶€ì—¬í•˜ì„¸ìš”.
    - ë…¼ë¦¬ì ì¸ íë¦„ì„ ê°€ì¡ŒëŠ”ê°€?
    - ì£¼ì¥ì´ ëª…í™•í•˜ê²Œ ì „ë‹¬ë˜ëŠ”ê°€?
    - ì ìˆ˜: [ì ìˆ˜]/10
    - í‰ê°€: [í‰ê°€ ë‚´ìš©]
    ë‹µë³€: {answer}
    """)
    chain = prompt_template | llm

    async with llm_semaphore:
        logic_eval = await chain.ainvoke({"answer": answer})
    return logic_eval.content

async def timing_agent_node(time_in_seconds: int) -> Dict[str, Any]:
    print("--- â±ï¸ ë°œí™” ì‹œê°„ í‰ê°€ ì‹œì‘ ---")
    if 90 <= time_in_seconds <= 120:
        score = 10
        evaluation = "ë§¤ìš° ì ì ˆí•œ ë°œí™” ì‹œê°„ì…ë‹ˆë‹¤."
    else:
        score = max(10 - abs(time_in_seconds - 105) // 5, 0)
        evaluation = "ë°œí™” ì‹œê°„ì´ ì ì • ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤."
    
    return {"score": score, "evaluation": evaluation}

async def final_report_node(eval_results: Dict[str, Any]) -> str:
    print("--- ğŸ“ ìµœì¢… ë³´ê³ ì„œ ìƒì„± ì‹œì‘ ---")
    prompt_template = PromptTemplate.from_template("""
    ì•„ë˜ëŠ” ë©´ì ‘ ë‹µë³€ì— ëŒ€í•œ ì—¬ëŸ¬ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤. ê° ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ í•˜ë‚˜ì˜ ìµœì¢… ë©´ì ‘ í‰ê°€ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ë³´ê³ ì„œëŠ” ì ìˆ˜ì™€ í‰ê°€ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    
    <í‰ê°€ ê²°ê³¼>
    - STAR ê¸°ë²• í‰ê°€: {star_eval}
    - ë…¼ë¦¬ì„± í‰ê°€: {logic_eval}
    - ë°œí™” ì‹œê°„ í‰ê°€: {timing_eval}

    <ìµœì¢… ë³´ê³ ì„œ>
    """)
    
    chain = prompt_template | llm

    async with llm_semaphore:
        final_report = await chain.ainvoke({
            "star_eval": eval_results["star_evaluation"],
            "logic_eval": eval_results["logic_evaluation"],
            "timing_eval": eval_results["timing_evaluation"]
        })
    return final_report.content

# --- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ ---
async def evaluate_full_answer(question: str, answer: str, time_in_seconds: int) -> Dict[str, Any]:
    # í‰ê°€ í•¨ìˆ˜ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œ
    star_eval = await star_agent_node(answer)
    logic_eval = await logic_agent_node(answer)
    timing_eval = await timing_agent_node(time_in_seconds)
    
    # í‰ê°€ ê²°ê³¼ë“¤ì„ ì·¨í•©
    eval_results = {
        "star_evaluation": star_eval,
        "logic_evaluation": logic_eval,
        "timing_evaluation": timing_eval
    }
    
    # ìµœì¢… ë³´ê³ ì„œ ìƒì„±
    final_report = await final_report_node(eval_results)
    
    return {
        "question": question,
        "answer": answer,
        "time_in_seconds": time_in_seconds,
        "evaluations": eval_results,
        "final_report": final_report
    }

if __name__ == '__main__':
    # ì´ íŒŒì¼ë§Œ ë‹¨ë…ìœ¼ë¡œ ì‹¤í–‰í–ˆì„ ë•Œ í…ŒìŠ¤íŠ¸
    async def test_main():
        sample_answer = "íŒ€ í”„ë¡œì íŠ¸ì—ì„œ ì‚¬ìš©ì ê´€ë¦¬ ê¸°ëŠ¥ì„ ê°œë°œí–ˆìŠµë‹ˆë‹¤. ì‚¬ìš©ìê°€ ë§ì•„ì§€ë©´ì„œ ë¡œë”©ì´ ëŠë ¤ì ¸ì„œ DB ì¿¼ë¦¬ë¥¼ ìµœì í™”í•˜ëŠ” ì‘ì—…ì„ ë§¡ì•˜ìŠµë‹ˆë‹¤. ì¸ë±ìŠ¤ë¥¼ ì¶”ê°€í•˜ê³  ì¡°ì¸ ë°©ì‹ì„ ë³€ê²½í•´ì„œ ë¡œë”© ì†ë„ë¥¼ 80% ê°œì„ í•˜ëŠ” ë° ì„±ê³µí–ˆìŠµë‹ˆë‹¤. ì´ ê²½í—˜ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”ì˜ ì¤‘ìš”ì„±ì„ ê¹¨ë‹¬ì•˜ìŠµë‹ˆë‹¤."
        report = await evaluate_full_answer("í”„ë¡œì íŠ¸ ê²½í—˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.", sample_answer, 100)
        print("\n=== ìµœì¢… ë³´ê³ ì„œ ===\n", report["final_report"])

    asyncio.run(test_main())